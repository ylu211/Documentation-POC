import fs from 'fs'
import path from 'path'
import fetch from 'node-fetch'

const diagramsDir = path.join(process.cwd(), '../docs/docs/diagrams')

async function queryOllama(prompt) {
  console.log('üîπ Envoi de la requ√™te au LLM...')
  const response = await fetch('http://localhost:11434/api/generate', {
    method: 'POST',
    headers: { 'Content-Type': 'application/json' },
    body: JSON.stringify({ model: 'llama2', prompt })
  })
  console.log('üîπ Requ√™te envoy√©e, attente r√©ponse...')
  
  const data = await response.json()
  console.log('üîπ R√©ponse re√ßue !')
  return data.text
}

async function generateDescriptions() {
  const files = fs.readdirSync(diagramsDir).filter(f => f.endsWith('.mmd'))

  for (const file of files) {
    const diagramPath = path.join(diagramsDir, file)
    console.log(`üìÇ Lecture du fichier ${file}`)
    const diagram = fs.readFileSync(diagramPath, 'utf-8')
    console.log(`üìù Diagramme lu, longueur : ${diagram.length} caract√®res`)

    console.log('üí¨ Envoi au LLM...')
    const prompt = `
    G√©n√®re une description concise pour une documentation technique √† partir d'un diagramme de s√©quence Mermaid.
    La description doit expliquer le flux et les composants principaux, en √©vitant les d√©tails superflus.
    Diagramme :
    ${diagram}
    `

    console.log(`‚ö° G√©n√©ration description pour ${file}...`)
    const description = await queryOllama(prompt)
    console.log('Finir la generation')

    const outputFile = diagramPath.replace('.mmd', '-description.md')
    console.log('Creation du fichier');
    fs.writeFileSync(outputFile, description, 'utf-8')
    console.log(`‚úÖ Fichier g√©n√©r√© : ${outputFile}`)
  }
}

generateDescriptions()
